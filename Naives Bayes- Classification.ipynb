{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0a6cbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66cca6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=pd.read_csv(\"Social_Network_Ads.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "397372b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>15691863</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>15706071</td>\n",
       "      <td>Male</td>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>15654296</td>\n",
       "      <td>Female</td>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>15755018</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>15594041</td>\n",
       "      <td>Female</td>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0    15624510    Male   19            19000          0\n",
       "1    15810944    Male   35            20000          0\n",
       "2    15668575  Female   26            43000          0\n",
       "3    15603246  Female   27            57000          0\n",
       "4    15804002    Male   19            76000          0\n",
       "..        ...     ...  ...              ...        ...\n",
       "395  15691863  Female   46            41000          1\n",
       "396  15706071    Male   51            23000          1\n",
       "397  15654296  Female   50            20000          1\n",
       "398  15755018    Male   36            33000          0\n",
       "399  15594041  Female   49            36000          1\n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37bd7422",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=pd.get_dummies(datasets,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac97ff5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>15691863</td>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>15706071</td>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>15654296</td>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>15755018</td>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>15594041</td>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID  Age  EstimatedSalary  Purchased  Gender_Male\n",
       "0    15624510   19            19000          0            1\n",
       "1    15810944   35            20000          0            1\n",
       "2    15668575   26            43000          0            0\n",
       "3    15603246   27            57000          0            0\n",
       "4    15804002   19            76000          0            1\n",
       "..        ...  ...              ...        ...          ...\n",
       "395  15691863   46            41000          1            0\n",
       "396  15706071   51            23000          1            1\n",
       "397  15654296   50            20000          1            0\n",
       "398  15755018   36            33000          0            1\n",
       "399  15594041   49            36000          1            0\n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "309b01b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=datasets.drop(\"User ID\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed5c738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    257\n",
       "1    143\n",
       "Name: Purchased, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"Purchased\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27a3ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "indep=datasets[[\"Age\",\"EstimatedSalary\",\"Gender_Male\"]]\n",
    "dep=datasets[\"Purchased\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "523b8168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  EstimatedSalary  Gender_Male\n",
       "0     19            19000            1\n",
       "1     35            20000            1\n",
       "2     26            43000            0\n",
       "3     27            57000            0\n",
       "4     19            76000            1\n",
       "..   ...              ...          ...\n",
       "395   46            41000            0\n",
       "396   51            23000            1\n",
       "397   50            20000            0\n",
       "398   36            33000            1\n",
       "399   49            36000            0\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b06a30d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "395    1\n",
       "396    1\n",
       "397    1\n",
       "398    0\n",
       "399    1\n",
       "Name: Purchased, Length: 400, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c46763e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(indep,dep,test_size=0.30,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd9e35ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92        79\n",
      "           1       0.87      0.80      0.84        41\n",
      "\n",
      "    accuracy                           0.89       120\n",
      "   macro avg       0.89      0.87      0.88       120\n",
      "weighted avg       0.89      0.89      0.89       120\n",
      "\n",
      "[[74  5]\n",
      " [ 8 33]]\n",
      "The f1_macro value for best parameter {}: 0.8354430379746836\n",
      "The accuracy_score value for best parameter {}: 0.8916666666666667\n",
      "The balanced_accuracy_score for best parameter {}: 0.8707934547699907\n",
      "The top_k_accuracy_score for best parameter {}: 1.0\n",
      "The average_precision_score value for best parameter {}: 0.7656397090286693\n",
      "The brier_score_loss for best parameter {}: 0.10833333333333334\n",
      "The log_loss for best parameter {}: 3.7417340926749163\n",
      "The precision_score for best parameter {}: 0.868421052631579\n",
      "The recall_score for best parameter {}: 0.8048780487804879\n",
      "The jaccard_score for best parameter {}: 0.717391304347826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajah\\anaconda3\\envs\\pugazh\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1745: UndefinedMetricWarning: 'k' (2) greater than or equal to 'n_classes' (2) will result in a perfect score and is therefore meaningless.\n",
      "  UndefinedMetricWarning,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report = classification_report(y_test, y_pred)              \n",
    "print(clf_report)\n",
    "print(cm)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_macro=f1_score(y_test,y_pred,)\n",
    "print(\"The f1_macro value for best parameter {}:\",f1_macro)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score=accuracy_score(y_test,y_pred)\n",
    "print(\"The accuracy_score value for best parameter {}:\",accuracy_score)\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score=balanced_accuracy_score(y_test,y_pred)\n",
    "print(\"The balanced_accuracy_score for best parameter {}:\",balanced_accuracy_score)\n",
    "\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "top_k_accuracy_score=top_k_accuracy_score(y_test,y_pred, k=2)\n",
    "print(\"The top_k_accuracy_score for best parameter {}:\",top_k_accuracy_score)\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision_score=average_precision_score(y_test, y_pred)\n",
    "print(\"The average_precision_score value for best parameter {}:\",average_precision_score)\n",
    "\n",
    "from sklearn.metrics import brier_score_loss\n",
    "brier_score_loss=brier_score_loss(y_test, y_pred)\n",
    "print(\"The brier_score_loss for best parameter {}:\",brier_score_loss)\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "log_loss=log_loss(y_test,y_pred)\n",
    "print(\"The log_loss for best parameter {}:\",log_loss)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score=precision_score(y_test,y_pred)\n",
    "print(\"The precision_score for best parameter {}:\",precision_score)\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score=recall_score(y_test,y_pred)\n",
    "print(\"The recall_score for best parameter {}:\",recall_score)\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "jaccard_score=jaccard_score(y_test,y_pred)\n",
    "print(\"The jaccard_score for best parameter {}:\",jaccard_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54d2e525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.78        79\n",
      "           1       0.54      0.32      0.40        41\n",
      "\n",
      "    accuracy                           0.68       120\n",
      "   macro avg       0.62      0.59      0.59       120\n",
      "weighted avg       0.65      0.68      0.65       120\n",
      "\n",
      "[[68 11]\n",
      " [28 13]]\n",
      "The f1_macro value for best parameter {}: 0.39999999999999997\n",
      "The accuracy_score value for best parameter {}: 0.675\n",
      "The balanced_accuracy_score for best parameter {}: 0.5889163322012967\n",
      "The top_k_accuracy_score for best parameter {}: 1.0\n",
      "The average_precision_score value for best parameter {}: 0.4050813008130081\n",
      "The brier_score_loss for best parameter {}: 0.325\n",
      "The log_loss for best parameter {}: 11.225175624777073\n",
      "The precision_score for best parameter {}: 0.5416666666666666\n",
      "The recall_score for best parameter {}: 0.3170731707317073\n",
      "The jaccard_score for best parameter {}: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajah\\anaconda3\\envs\\pugazh\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1745: UndefinedMetricWarning: 'k' (2) greater than or equal to 'n_classes' (2) will result in a perfect score and is therefore meaningless.\n",
      "  UndefinedMetricWarning,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report = classification_report(y_test, y_pred)              \n",
    "print(clf_report)\n",
    "print(cm)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_macro=f1_score(y_test,y_pred,)\n",
    "print(\"The f1_macro value for best parameter {}:\",f1_macro)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score=accuracy_score(y_test,y_pred)\n",
    "print(\"The accuracy_score value for best parameter {}:\",accuracy_score)\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score=balanced_accuracy_score(y_test,y_pred)\n",
    "print(\"The balanced_accuracy_score for best parameter {}:\",balanced_accuracy_score)\n",
    "\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "top_k_accuracy_score=top_k_accuracy_score(y_test,y_pred, k=2)\n",
    "print(\"The top_k_accuracy_score for best parameter {}:\",top_k_accuracy_score)\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision_score=average_precision_score(y_test, y_pred)\n",
    "print(\"The average_precision_score value for best parameter {}:\",average_precision_score)\n",
    "\n",
    "from sklearn.metrics import brier_score_loss\n",
    "brier_score_loss=brier_score_loss(y_test, y_pred)\n",
    "print(\"The brier_score_loss for best parameter {}:\",brier_score_loss)\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "log_loss=log_loss(y_test,y_pred)\n",
    "print(\"The log_loss for best parameter {}:\",log_loss)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score=precision_score(y_test,y_pred)\n",
    "print(\"The precision_score for best parameter {}:\",precision_score)\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score=recall_score(y_test,y_pred)\n",
    "print(\"The recall_score for best parameter {}:\",recall_score)\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "jaccard_score=jaccard_score(y_test,y_pred)\n",
    "print(\"The jaccard_score for best parameter {}:\",jaccard_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5bbefa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajah\\anaconda3\\envs\\pugazh\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rajah\\anaconda3\\envs\\pugazh\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rajah\\anaconda3\\envs\\pugazh\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rajah\\anaconda3\\envs\\pugazh\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1745: UndefinedMetricWarning: 'k' (2) greater than or equal to 'n_classes' (2) will result in a perfect score and is therefore meaningless.\n",
      "  UndefinedMetricWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79        79\n",
      "           1       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.66       120\n",
      "   macro avg       0.33      0.50      0.40       120\n",
      "weighted avg       0.43      0.66      0.52       120\n",
      "\n",
      "[[79  0]\n",
      " [41  0]]\n",
      "The f1_macro value for best parameter {}: 0.0\n",
      "The accuracy_score value for best parameter {}: 0.6583333333333333\n",
      "The balanced_accuracy_score for best parameter {}: 0.5\n",
      "The top_k_accuracy_score for best parameter {}: 1.0\n",
      "The average_precision_score value for best parameter {}: 0.3416666666666667\n",
      "The brier_score_loss for best parameter {}: 0.3416666666666667\n",
      "The log_loss for best parameter {}: 11.800748601594483\n",
      "The precision_score for best parameter {}: 0.0\n",
      "The recall_score for best parameter {}: 0.0\n",
      "The jaccard_score for best parameter {}: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajah\\anaconda3\\envs\\pugazh\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "classifier = BernoulliNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report = classification_report(y_test, y_pred)              \n",
    "print(clf_report)\n",
    "print(cm)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_macro=f1_score(y_test,y_pred,)\n",
    "print(\"The f1_macro value for best parameter {}:\",f1_macro)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score=accuracy_score(y_test,y_pred)\n",
    "print(\"The accuracy_score value for best parameter {}:\",accuracy_score)\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score=balanced_accuracy_score(y_test,y_pred)\n",
    "print(\"The balanced_accuracy_score for best parameter {}:\",balanced_accuracy_score)\n",
    "\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "top_k_accuracy_score=top_k_accuracy_score(y_test,y_pred, k=2)\n",
    "print(\"The top_k_accuracy_score for best parameter {}:\",top_k_accuracy_score)\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision_score=average_precision_score(y_test, y_pred)\n",
    "print(\"The average_precision_score value for best parameter {}:\",average_precision_score)\n",
    "\n",
    "from sklearn.metrics import brier_score_loss\n",
    "brier_score_loss=brier_score_loss(y_test, y_pred)\n",
    "print(\"The brier_score_loss for best parameter {}:\",brier_score_loss)\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "log_loss=log_loss(y_test,y_pred)\n",
    "print(\"The log_loss for best parameter {}:\",log_loss)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score=precision_score(y_test,y_pred)\n",
    "print(\"The precision_score for best parameter {}:\",precision_score)\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score=recall_score(y_test,y_pred)\n",
    "print(\"The recall_score for best parameter {}:\",recall_score)\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "jaccard_score=jaccard_score(y_test,y_pred)\n",
    "print(\"The jaccard_score for best parameter {}:\",jaccard_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61b7abc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.53      0.60        79\n",
      "           1       0.36      0.51      0.42        41\n",
      "\n",
      "    accuracy                           0.53       120\n",
      "   macro avg       0.52      0.52      0.51       120\n",
      "weighted avg       0.57      0.52      0.54       120\n",
      "\n",
      "[[42 37]\n",
      " [20 21]]\n",
      "The f1_macro value for best parameter {}: 0.42424242424242425\n",
      "The accuracy_score value for best parameter {}: 0.525\n",
      "The balanced_accuracy_score for best parameter {}: 0.5219203457857363\n",
      "The top_k_accuracy_score for best parameter {}: 1.0\n",
      "The average_precision_score value for best parameter {}: 0.352116624614522\n",
      "The brier_score_loss for best parameter {}: 0.475\n",
      "The log_loss for best parameter {}: 16.40616533012355\n",
      "The precision_score for best parameter {}: 0.3620689655172414\n",
      "The recall_score for best parameter {}: 0.5121951219512195\n",
      "The jaccard_score for best parameter {}: 0.2692307692307692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajah\\anaconda3\\envs\\pugazh\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1745: UndefinedMetricWarning: 'k' (2) greater than or equal to 'n_classes' (2) will result in a perfect score and is therefore meaningless.\n",
      "  UndefinedMetricWarning,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "classifier =ComplementNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report = classification_report(y_test, y_pred)              \n",
    "print(clf_report)\n",
    "print(cm)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_macro=f1_score(y_test,y_pred,)\n",
    "print(\"The f1_macro value for best parameter {}:\",f1_macro)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score=accuracy_score(y_test,y_pred)\n",
    "print(\"The accuracy_score value for best parameter {}:\",accuracy_score)\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score=balanced_accuracy_score(y_test,y_pred)\n",
    "print(\"The balanced_accuracy_score for best parameter {}:\",balanced_accuracy_score)\n",
    "\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "top_k_accuracy_score=top_k_accuracy_score(y_test,y_pred, k=2)\n",
    "print(\"The top_k_accuracy_score for best parameter {}:\",top_k_accuracy_score)\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision_score=average_precision_score(y_test, y_pred)\n",
    "print(\"The average_precision_score value for best parameter {}:\",average_precision_score)\n",
    "\n",
    "from sklearn.metrics import brier_score_loss\n",
    "brier_score_loss=brier_score_loss(y_test, y_pred)\n",
    "print(\"The brier_score_loss for best parameter {}:\",brier_score_loss)\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "log_loss=log_loss(y_test,y_pred)\n",
    "print(\"The log_loss for best parameter {}:\",log_loss)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score=precision_score(y_test,y_pred)\n",
    "print(\"The precision_score for best parameter {}:\",precision_score)\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score=recall_score(y_test,y_pred)\n",
    "print(\"The recall_score for best parameter {}:\",recall_score)\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "jaccard_score=jaccard_score(y_test,y_pred)\n",
    "print(\"The jaccard_score for best parameter {}:\",jaccard_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "366706a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93        79\n",
      "           1       0.91      0.78      0.84        41\n",
      "\n",
      "    accuracy                           0.90       120\n",
      "   macro avg       0.90      0.87      0.88       120\n",
      "weighted avg       0.90      0.90      0.90       120\n",
      "\n",
      "[[76  3]\n",
      " [ 9 32]]\n",
      "The f1_macro value for best parameter {}: 0.8421052631578947\n",
      "The accuracy_score value for best parameter {}: 0.9\n",
      "The balanced_accuracy_score for best parameter {}: 0.8712565606668725\n",
      "The top_k_accuracy_score for best parameter {}: 1.0\n",
      "The average_precision_score value for best parameter {}: 0.788588850174216\n",
      "The brier_score_loss for best parameter {}: 0.1\n",
      "The log_loss for best parameter {}: 3.4538976294268244\n",
      "The precision_score for best parameter {}: 0.9142857142857143\n",
      "The recall_score for best parameter {}: 0.7804878048780488\n",
      "The jaccard_score for best parameter {}: 0.7272727272727273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajah\\anaconda3\\envs\\pugazh\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1745: UndefinedMetricWarning: 'k' (2) greater than or equal to 'n_classes' (2) will result in a perfect score and is therefore meaningless.\n",
      "  UndefinedMetricWarning,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "classifier =CategoricalNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report = classification_report(y_test, y_pred)              \n",
    "print(clf_report)\n",
    "print(cm)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_macro=f1_score(y_test,y_pred,)\n",
    "print(\"The f1_macro value for best parameter {}:\",f1_macro)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score=accuracy_score(y_test,y_pred)\n",
    "print(\"The accuracy_score value for best parameter {}:\",accuracy_score)\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score=balanced_accuracy_score(y_test,y_pred)\n",
    "print(\"The balanced_accuracy_score for best parameter {}:\",balanced_accuracy_score)\n",
    "\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "top_k_accuracy_score=top_k_accuracy_score(y_test,y_pred, k=2)\n",
    "print(\"The top_k_accuracy_score for best parameter {}:\",top_k_accuracy_score)\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision_score=average_precision_score(y_test, y_pred)\n",
    "print(\"The average_precision_score value for best parameter {}:\",average_precision_score)\n",
    "\n",
    "from sklearn.metrics import brier_score_loss\n",
    "brier_score_loss=brier_score_loss(y_test, y_pred)\n",
    "print(\"The brier_score_loss for best parameter {}:\",brier_score_loss)\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "log_loss=log_loss(y_test,y_pred)\n",
    "print(\"The log_loss for best parameter {}:\",log_loss)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score=precision_score(y_test,y_pred)\n",
    "print(\"The precision_score for best parameter {}:\",precision_score)\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score=recall_score(y_test,y_pred)\n",
    "print(\"The recall_score for best parameter {}:\",recall_score)\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "jaccard_score=jaccard_score(y_test,y_pred)\n",
    "print(\"The jaccard_score for best parameter {}:\",jaccard_score)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
